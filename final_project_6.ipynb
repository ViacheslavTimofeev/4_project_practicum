{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1c27f5cb-b24b-44ab-867d-c640936cb768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France     5014\n",
      "Germany    2509\n",
      "Spain      2477\n",
      "Name: Geography, dtype: int64\n",
      "0    4804\n",
      "1    1196\n",
      "Name: Exited, dtype: int64\n",
      "1    1196\n",
      "0     979\n",
      "Name: Exited, dtype: int64\n",
      "0.5523091423185674   6\n",
      "0.57397504456328   14   15\n",
      "0.11340206185567009\n",
      "0.6557291822178353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nplt.figure()\\nplt.plot(fpr, tpr)\\nplt.xlim([0.0, 1.0])\\nplt.ylim([0.0, 1.0])\\nplt.xlabel('False Positive Rate')\\nplt.ylabel('True Positive Rate')\\nplt.title('ROC-кривая')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "np.random.seed(12345)\n",
    "\n",
    "data = pd.read_csv('D:/Churn.csv')\n",
    "\n",
    "data = data.drop(['RowNumber', 'Surname', 'CustomerId'], axis=1)\n",
    "\n",
    "data['Tenure'] = data['Tenure'].fillna(1)\n",
    "\n",
    "print(data['Geography'].value_counts())\n",
    "data = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "features = data.drop('Exited', axis=1)\n",
    "target = data['Exited']\n",
    "\n",
    "# соотношение выборок: 3:1:1\n",
    "features_train, features_rem, target_train, target_rem = train_test_split(features, target, train_size=0.6)\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_rem, target_rem, test_size=0.2)\n",
    "\n",
    "# первая техника: upsampling. target_train.value_counts до: 0: 4804, 1: 1196; после: 0: 4804, 1: 3588\n",
    "'''\n",
    "ratio = len(data.loc[data['Exited'] == 0]) // len(data.loc[data['Exited'] == 1])\n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=12345)\n",
    "    \n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "features_upsampled_train, target_upsampled_train = upsample(features_train, target_train, ratio)\n",
    "'''\n",
    "# вторая техника: downsampling. target_train.value_counts до: 0: 4804, 1: 1196; после: 0: 979, 1: 1196\n",
    "print(target_train.value_counts())\n",
    "fraction = 0.2037\n",
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    features_downsampled = pd.concat([features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])\n",
    "    target_downsampled = pd.concat([target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
    "    features_downsampled, target_downsampled = shuffle(features_downsampled, target_downsampled, random_state=12345)\n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "features_downsampled_train, target_downsampled_train = downsample(features_train, target_train, fraction)\n",
    "print(target_downsampled_train.value_counts())\n",
    "\n",
    "# 1 model: tree classifier\n",
    "best_score = 0\n",
    "best_depth = 0\n",
    "for depth in range(1, 14):\n",
    "    model_decision_tree = DecisionTreeClassifier(max_depth=depth)\n",
    "    model_decision_tree.fit(features_train, target_train)\n",
    "    model_decision_tree_predictions = model_decision_tree.predict(features_valid)\n",
    "    score = f1_score(target_valid, model_decision_tree_predictions)\n",
    "    if score > best_score:\n",
    "        best_depth = depth\n",
    "        best_score = score\n",
    "print(best_score, ' ', best_depth)\n",
    "\n",
    "# 2 model: random forest classifier\n",
    "best_score = 0\n",
    "best_depth = 0\n",
    "best_est = 0\n",
    "for est in range(10, 23):\n",
    "    for depth in range(1, 18):\n",
    "        model_forest = RandomForestClassifier(n_estimators=est, max_depth=depth)\n",
    "        model_forest.fit(features_train, target_train)\n",
    "        forest_predict = model_forest.predict(features_valid)\n",
    "        score = f1_score(target_valid, forest_predict)\n",
    "        if score > best_score:\n",
    "            best_depth = depth\n",
    "            best_score = score\n",
    "            best_est = est\n",
    "print(best_score, ' ', best_depth, ' ', best_est)            \n",
    "  \n",
    "# 3 model: logistic regression\n",
    "model = LogisticRegression(solver='liblinear', max_iter=100)\n",
    "model.fit(features_train, target_train)\n",
    "predict_regr = model.predict(features_valid)\n",
    "print(f1_score(target_valid, predict_regr))\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(target_valid, probabilities_one_valid)\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print(auc_roc)\n",
    "'''\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC-кривая')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef3a238-72fc-4c5c-99e2-8170bf376b50",
   "metadata": {},
   "source": [
    "# Результаты до обработки на валидационной выборке\n",
    "## f1_score\n",
    "### tree classifier model: 0.5523\n",
    "### random forest: 0.5739\n",
    "### logistic regression: 0.1134\n",
    "### auc_roc score: 0.6557"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8feb460-1b64-4051-97a8-d14aa3c045f0",
   "metadata": {},
   "source": [
    "# Upsampling: результаты на тестовой выборке\n",
    "## f1_score\n",
    "### tree classifier model: 0.5885\n",
    "### random forest: 0.6441\n",
    "### logistic regression: 0.4538\n",
    "### auc_roc score: 0.6999"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4035ff6-6e2a-466f-bcf1-84a09a1d982c",
   "metadata": {},
   "source": [
    "# Downsampling: результаты на тестовой выборке\n",
    "## f1_score\n",
    "### tree classifier model: 0.5871\n",
    "### random forest: 0.5920\n",
    "### logistic regression: 0.430\n",
    "### auc_roc score: 0.6983"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95376855-0290-4c9c-934d-a73788bd2bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
